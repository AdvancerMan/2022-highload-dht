* Имеем lua скрипты [GET](../scripts/get.lua) и [PUT](../scripts/put.lua), генерирующие соответсвующее запросы со случайными ключами и значениями вида key n value m
* В БД изначально `130` файлов суммарным размером `1,3 Гб` (с записями вплоть до key 50кк, value 50kk)
* `5 Мб` flushThreshold
* Размер очереди `1000`


Прогрев за 30 секунд сервер программой wrk, запускаем профилирование put запросов, потом сразу же запускаем профилирование get

`wrk2 -c 64 -t 8 -d 2m -R 30000 -s put.lua --latency http://localhost:19234 > wrk-put-report0`

`wrk2 -c 64 -t 8 -d 2m -R 10000 -s get.lua --latency http://localhost:19234 > wrk-get-report0`

* 64 соединений
* 8 потоков
* 2 минуты
* 10000 запросов/сек для get
* 30000 запросов/сек для put

Профилировщик запустим в трёх режимах: cpu, alloc и lock

`./profiler.sh -f put.html -e cpu,alloc, lock --chunktime 1s start Server`

## Тест 0
 
Проверим новую реализацию тестами из stage 1:

[wrk-put-report](wrk/wrk-put-report0), [wrk-get-report](wrk/wrk-get-report0)

Получилось, что сервис справляется со старыми цифрами, сохраняется факт большей производительности на put запросы.

## Тест 1

`fifoRareness = 3` - проверим нашу очередь в режиме, когда каждый третий запрос обрабатывается в режиме FIFO

[wrk-put-report](wrk/wrk-put-report1), [wrk-get-report](wrk/wrk-get-report1)

[сpu](html/cpu1.html), [alloc](html/cpu1.html), [lock](html/cpu1.html)

Получили:
* Среднюю задержку в `1.31ms` для put запросов. Что говорит, что на этих цифрах сервер уже "напрягается"
* Среднюю задержку в `1.04ms` для get запросов

По сравнению со stage1 при профилировании наблюдаем:
* На `Lock` видим 58% сэмплов queue.take(), 23% queue.size() и 15% queue.offer()
* На `CPU` видим 15% сэмплов queue.take(), 1.76% queue.offer(), 0.74% queue.size()

## Тест 2

`fifoRareness = 1` - проверим нашу очередь в режиме, когда каждый запрос обрабатывается в режиме FIFO

[wrk-put-report](wrk/wrk-put-report2), [wrk-get-report](wrk/wrk-get-report2)

[сpu](html/cpu2.html), [alloc](html/cpu2.html), [lock](html/cpu2.html)

Получили:
* Среднюю задержку в `1.27ms` для put запросов.
* Среднюю задержку в `0.96ms` для get запросов.

В среднем задержки получились те же, но они получили более равномерное распределение. Нет запросов, которым не повезло, и до которых рабочие потоки добираются не сразу.
Не видим снижения производительности ввиду эффекта, обсуждаемого на занятии, когда пока мы обрабатывали запросы, следующие затаймаутились, обработав их, затаймаутились следующие.

## Тест 3

Не будем отказывать запросам, когда очередь заполнена (rejectWhenOverloaded = `false`) и будем уменьшать размер очереди.
Уменьшим размер очереди до `64`

[wrk-put-report](wrk/wrk-put-report3), [wrk-get-report](wrk/wrk-get-report3),

Видим, что средние задержки примерно те же, но при этом их распределение не такое равномерное, и при 99.9% мы видим резкий скачок.
Появляются потоки, которые блокируются на очереди


## Тест 4
Уменьшим размер очереди до `32`

[wrk-put-report](wrk/wrk-put-report4), [wrk-get-report](wrk/wrk-get-report4)

[сpu](html/cpu4.html), [alloc](html/cpu4.html), [lock](html/cpu4.html)

На этой цифре мы видим, как производительность сервиса сильно упала и для запросов мы имеем неприемлемые задержки.
Получается эффект, когда потоки борются за очередь, блокируются на том, чтобы вставить туда элемент, в результате
потоки делают сильно меньше полезной работы, так как почти всегда заблокированы, и heatMap по большей части бледно-розовая.

Подтверждение мы видим при профилировании:
* На `CPU` мы видим, что одинаково большое время, 23 - 24% всех сэмплов, воркеры тратят на queue.take, а селекторы на lockAndDoSelect()
* На `Lock` мы видим, как 53% сэмплов приходится на queue.take() и как 38% на queue.offer()

### Сравнение с предыдущей реализаций

`1 Мб` flushThreshold, put Rate = `60000`, get Rate = `45000`

[wrk-put-report-new](wrk/compare/wrk-put-report-new), [wrk-put-report-old](wrk/compare/wrk-put-report-old)

[wrk-get-report-new](wrk/compare/wrk-get-report-new), [wrk-get-report-old](wrk/compare/wrk-get-report-old)

Получили:
* задержки для put в перегруженном режиме уменьшились в два раза
* для get видим уменьшение средней задержки и более равномерное распределение






