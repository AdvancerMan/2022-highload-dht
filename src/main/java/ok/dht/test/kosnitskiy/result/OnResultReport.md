Была создана база, занимающая 6.4Gb места, имеющая 768 файлов по 8.4мб каждый. Размер каждой записи составил 200кб

Рассмотрим GET запросы
Заметим, что когда мы рассматриваем лучшие случаи - получаем результат одного и того же ключа, база показывает результаты
в десятки раз лучше, чем когда ключа нет или ключи разные. 
Оно и понятно, когда ключ запрашивается один и тот же, происходит кеширование этой записи в InMemory части базы данных, 
что позволяет в конечном счете его очень быстро и четко получать снова и снова, если это потребуется

С другой стороны, когда ключа в базе нет, чтобы доказать этот факт базе приходится пройтись по всем файлам, начиная
с самого нового и заканчивая самым старым. Это занимает много времени от того и видим критическое падение производительности.
Для решения этой проблемы нам стоило бы реализовать фильтр Блума:
Если элемент существет в базе, то фильтр Блума никогда не обманет и скажет о его существовании
Если элемент не существует в базе, то фильтр Блума с высокой вероятностью скажет, что его там нет (но иногда может соврать)
Дополнение базы фильтром блума позволит существенно сократить время выполнения запросов с несущ. ключами

Если же ключи разные, то ситуация становится еще хуже - нам приходится искать по всей базе начиная с самого свежего файла,
заканчивая самым старым (прямо как с несуществующим ключом), однако теперь нам еще надо будет подгружать найденное значение
и отправлять его клиенту. Это поджирает еще немного производительности.

Теперь поговорим про PUT запросы
Заметим, что лучший случай и худший случай работают очень быстро, на уровне лучшего случая GET запроса по скорости
и не особо отличаются даже друг от друга по производительности. Это связано с тем, что худший случай лишь заставляет нас
асинхронно переходить к записи новых файлов на диск, отсюда и небольшая потеря в производительности, когда как в лучшем
случае происходит перезапись одного и того же ключа в InMemory хранилище.

Это все позволяет нам сделать вывод, что LSM дерево действительно очень хорошо подходит для быстрой записи новых данных,
даже если мы записываем абсолютно разные ключи и значения, однако очень плохо подходит для быстрого чтения данных,
особенно учитывая, что в реальной жизни ключи скорее всего будут всегда разные, а так же будет много запросов на несуществующие ключи.

Рассмотрим нагрузку, которую способна выдержать база в данный момент с цифрами:

GET:
Если говорить про самый популярный кейс - разные существующие ключи, то наша производительность останавливается примерно на уровне
500 GET запросов в секунду. Повышение планки до 600 еще отрабатывает +- адекватно, однако MAX время очень сильно подскакивает
По результатам стресс теста, можно заметить, что мы способны обрабатывать в среднем 700-800 GET запросов несуществующих ключей 
в секунду. Продолжая увеличивать нагрузку мы начинаем получать непозволительную задержку на ответ. Особенно сильно пугает MAX время ответа,
которое при переходе с 800 на 900 запросов увеличилось в 4 раза - с 9 до 37 ms!
С другой стороны если мы рассматриваем лучший случай GET с получением одного и того же ключа, то мы можем рассчитывать
на обработку 17000-18000 запросов в секунду. Что лучше обычного плохого случая более чем в 20 раз! В некоторых узких
кейсах эта информация может оказаться довольно важной

При анализе PUT замечаем, что даже при "худшем" случае мы легко сможем выдержать 15000 запросов в секунду. При рассмотрении
наилучшего случая максимальная адекватная нагрузка возрастает до 17000-18000 запросов в секунду.